# CFLAG-BD: Blockchain-Based Clustered Federated Learning with Deduplication of Model Weights

## This repository contains the source code, models, experiments, and documentation for the paper:

> **Blockchain-Based Clustered Federated Learning with Deduplication of Model Weights**  
> Aliyu Garba, Universiti Teknologi PETRONAS  
> Manuscript ID: BCRA-D-24-00448 (Under Review, *Blockchain: Research and Applications*)

---

## Overview

CFLAG-BD is a privacy-preserving and communication-efficient federated learning framework that:
- Dynamically clusters clients based on multi-dimensional criteria (data similarity, processing power, reliability, and architecture).
- Integrates a blockchain-based deduplication mechanism to prevent redundant model updates.
- Supports deployment in heterogeneous edge environments (e.g., IoT, mobile, healthcare).
- Achieves scalability up to 10,000 clients with minimal blockchain overhead and high model convergence.

---

## Requirements

- Python 3.8+
- VS Code or any compatible IDE (e.g., PyCharm, Jupyter)
- PyTorch â‰¥ 1.10
- Packages:
  - `numpy`
  - `scikit-learn`
  - `matplotlib`
  - `tqdm`
  - `seaborn`
  - `flask` *(for simulated blockchain)*
  - `networkx`
- Optional: 
  - Docker + Hyperledger Fabric (for actual blockchain deployment)
  - CUDA-enabled GPU for large-scale simulation

> Use the provided [`requirements.txt`](./requirements.txt) to install dependencies:
```bash
pip install -r requirements.txt
```
## Project Structure
```bash
CFLAG-BD/
â”œâ”€â”€ main_experiment.py               # Main orchestration for training and evaluation
â”œâ”€â”€ cflag_bd_algorithm.py           # Core implementation of CFLAG-BD logic
â”œâ”€â”€ memory_efficient_cflagbd.py     # Memory-optimized federated simulation
â”œâ”€â”€ baseline_algorithms.py          # Implementations of CQFL, IFCA, FedAvg, FedProx, LayerCFL
â”œâ”€â”€ model_architectures.py          # MLP, CNN, LSTM models
â”œâ”€â”€ lazy_dataset.py                 # Dataset wrapper with partitioning for federated use
â”œâ”€â”€ enhanced_client.py              # Federated client logic with clustering hooks
â”œâ”€â”€ learning_rate_scheduler.py      # Adaptive LR strategy
â”œâ”€â”€ hardware_profiler.py            # Emulates heterogeneous hardware benchmarks
â”œâ”€â”€ multi_dataset_support.py        # Switching between CIFAR, FMNIST, HAR datasets
â”œâ”€â”€ monitored_execution.py          # Resource/time profiling
â”œâ”€â”€ analyze_convergence.py          # Plot and log convergence metrics
â”œâ”€â”€ results/                        # Folder with visualizations and logs
â””â”€â”€ README.md
```
## Running Experiments
### Simulate Federated Learning with CFLAG-BD
```bash
python main_experiment.py --dataset cifar10 --algorithm cflag-bd --clients 1000
```
## Parameters
```
[-h] [--results_dir RESULTS_DIR] [--save_plots]
                          [--experiment {single,comparative,ablation,scalability,all}] [--dataset DATASET]
                          [--method METHOD] [--num_clients NUM_CLIENTS] [--num_rounds NUM_ROUNDS]
                          [--local_epochs LOCAL_EPOCHS] [--batch_size BATCH_SIZE] [--client_fraction CLIENT_FRACTION]
                          [--num_clusters NUM_CLUSTERS] [--dedup_threshold DEDUP_THRESHOLD] [--fedprox_mu FEDPROX_MU]
                          [--quantization_bits QUANTIZATION_BITS] [--non_iid] [--use_blockchain] [--dynamic_lr]
                          [--lr_schedule {step,exponential,cosine,adaptive,cyclic}]
```
## Optional arguments:
    --clusters: Number of client clusters (e.g., 5)
    --dedup: Enable deduplication logic
    --rounds: Communication rounds (default: 50)

## Run Baselines              
```bash
  python experiment_runner.py --baseline fedprox
```
## Scalability Testing (10,000 clients)
```bash
python memory_efficient_cflagbd.py --clients 10000
```
## Evaluation Metrics
- Classification accuracy (global and per cluster)
- Communication cost (per round & cumulative)
- Convergence speed (accuracy vs. round)
- Storage footprint per client and block
- Blockchain overhead (block time, consensus time)
- Statistical significance (p-values, Cohenâ€™s d)
- Scalability (training time across 100â€“10,000 clients) 
## Datasets Used
- [`Fashion-MNIST`](https://github.com/zalandoresearch/fashion-mnist)
- [`CIFAR-10`](https://www.cs.toronto.edu/~kriz/cifar.html)
  Use the **--dataset** flag to specify which one to load.
## Citation
If you use this work, please cite it as:
```bash
@article{cflagbd2025,
  title={Blockchain-Based Clustered Federated Learning with Deduplication of Model Weights},
  author={Mamman, Aliyu and others},
  journal={Blockchain: Research and Applications},
  year={2025},
  note={Under Review}
}
```

## Contact

For collaborations, questions, or contributions:

Aliyu Garba
ðŸ“§ engrabusadik@gmail.com
ðŸ”— https://github.com/username/CFLAG-BD
